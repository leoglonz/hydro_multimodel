{"cells":[{"cell_type":"markdown","metadata":{"id":"q1jGJFeaF0oG"},"source":["### Running bulk of multimodel testing\n","\n","This is equivalent to that present in the multimodel wrapper.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1832,"status":"ok","timestamp":1707705234766,"user":{"displayName":"Leo Lonzarich","userId":"03094207546900081501"},"user_tz":360},"id":"2Vt-fsprDO_u","outputId":"c300c26f-3e5f-4134-c3f5-a0182475218a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/5l/9brv6cdn1b97f82knqyjcb4m0000gn/T/ipykernel_16423/1401552018.py:12: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n","/Users/leoglonz/Desktop/water/hydro_multimodel/MODELS/test_dp_HBV_dynamic.py:58: SyntaxWarning: invalid escape sequence '\\d'\n","  rootDatabase = os.path.join(os.path.sep, 'D:\\data', 'Camels')  # CAMELS dataset root directory\n","/Users/leoglonz/Desktop/water/hydro_multimodel/MODELS/test_dp_HBV_dynamic.py:61: SyntaxWarning: invalid escape sequence '\\d'\n","  rootOut = os.path.join(os.path.sep, 'D:\\data\\model_runs', 'rnnStreamflow')  # Model output root directory\n"]},{"name":"stdout","output_type":"stream","text":["loading package hydroDL\n"]}],"source":["from config.read_configurations import config_hbv as hbvArgs\n","from config.read_configurations import config_prms as prmsArgs\n","from config.read_configurations import config_sacsma as sacsmaArgs\n","from config.read_configurations import config_sacsma_snow as sacsmaSnowArgs\n","from config.read_configurations import config_hbv_hydrodl as hbvhyArgs_d\n","\n","\n","import torch\n","import os\n","import platform\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import scipy.stats\n","# from post import plot\n","\n","from core.utils.randomseed_config import randomseed_config\n","from core.utils.master import create_output_dirs\n","from MODELS.loss_functions.get_loss_function import get_lossFun\n","from MODELS.test_dp_HBV_dynamic import test_dp_hbv\n","from core.data_processing.data_loading import loadData\n","from core.data_processing.normalization import transNorm\n","from core.utils.randomseed_config import randomseed_config\n","from core.data_processing.model import (\n","    take_sample_test,\n","    converting_flow_from_ft3_per_sec_to_mm_per_day\n",")\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","\n","# Set path to `hydro_multimodel_results` directory.\n","if platform.system() == 'Darwin':\n","    # For mac os\n","    out_dir = '/Users/leoglonz/Desktop/water/data/model_runs/hydro_multimodel_results'\n","    # Some operations are not yet working with MPS, so we might need to set some environment variables to use CPU fall instead\n","    # %env PYTORCH_ENABLE_MPS_FALLBACK=1\n","\n","elif platform.system() == 'Windows':\n","    # For windows\n","    out_dir = 'D:\\\\data\\\\model_runs\\\\hydro_multimodel_results\\\\'\n","\n","elif platform.system() == 'Linux':\n","    # For Colab\n","    out_dir = '/content/drive/MyDrive/Colab/data/model_runs/hydro_multimodel_results'\n","\n","else:\n","    raise ValueError('Unsupported operating system.')\n","\n","\n","##-----## Multi-model Parameters ##-----##\n","##--------------------------------------##\n","# Setting dictionaries to separately manage each diff model's attributes.\n","models = {'dPLHBV_dyn': None, 'SACSMA_snow':None, 'marrmot_PRMS':None}  # 'HBV':None, 'hbvhy': None, 'SACSMA_snow':None, 'SACSMA':None,\n","args_list = {'dPLHBV_dyn': hbvhyArgs_d, 'SACSMA_snow':sacsmaSnowArgs, 'marrmot_PRMS':prmsArgs}   # 'hbvhy': hbvhyArgs, 'HBV' : hbvArgs, 'SACSMA_snow':None, 'SACSMA': sacsmaArgs,\n","ENSEMBLE_TYPE = 'max'  # 'median', 'avg', 'max', 'softmax'\n","\n","# Load test observations and predictions from a prior run.\n","pred_path = os.path.join(out_dir, 'multimodels', '671_sites_dp', 'output', 'preds_671_dPLHBVd_SACSMASnow_PRMS.npy')\n","obs_path = os.path.join(out_dir, 'multimodels', '671_sites_dp', 'output', 'obs_671_dPLHBVd_SACSMASnow_PRMS.npy')\n","preds = np.load(pred_path, allow_pickle=True).item()\n","obs = np.load(obs_path, allow_pickle=True).item()\n","\n","model_output = preds\n","y_obs = obs"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1707706633956,"user":{"displayName":"Leo Lonzarich","userId":"03094207546900081501"},"user_tz":360},"id":"typgVyc9DO_z"},"outputs":[],"source":["def calFDC(data):\n","    # data = Ngrid * Nday\n","    Ngrid, Nday = data.shape\n","    FDC100 = np.full([Ngrid, 100], np.nan)\n","    for ii in range(Ngrid):\n","        tempdata0 = data[ii, :]\n","        tempdata = tempdata0[~np.isnan(tempdata0)]\n","        # deal with no data case for some gages\n","        if len(tempdata)==0:\n","            tempdata = np.full(Nday, 0)\n","        # sort from large to small\n","        temp_sort = np.sort(tempdata)[::-1]\n","        # select 100 quantile points\n","        Nlen = len(tempdata)\n","        ind = (np.arange(100)/100*Nlen).astype(int)\n","        FDCflow = temp_sort[ind]\n","        if len(FDCflow) != 100:\n","            raise Exception('unknown assimilation variable')\n","        else:\n","            FDC100[ii, :] = FDCflow\n","\n","    return FDC100\n","\n","\n","def statError(pred, target):\n","    ngrid, nt = pred.shape\n","    with warnings.catch_warnings():\n","        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n","    # Bias\n","        Bias = np.nanmean(pred - target, axis=1)\n","        # RMSE\n","        RMSE = np.sqrt(np.nanmean((pred - target)**2, axis=1))\n","        # ubRMSE\n","        predMean = np.tile(np.nanmean(pred, axis=1), (nt, 1)).transpose()\n","        targetMean = np.tile(np.nanmean(target, axis=1), (nt, 1)).transpose()\n","        predAnom = pred - predMean\n","        targetAnom = target - targetMean\n","        ubRMSE = np.sqrt(np.nanmean((predAnom - targetAnom)**2, axis=1))\n","        # FDC metric\n","        predFDC = calFDC(pred)\n","        targetFDC = calFDC(target)\n","        FDCRMSE = np.sqrt(np.nanmean((predFDC - targetFDC) ** 2, axis=1))\n","    # rho R2 NSE\n","        Corr = np.full(ngrid, np.nan)\n","        CorrSp = np.full(ngrid, np.nan)\n","        R2 = np.full(ngrid, np.nan)\n","        NSE = np.full(ngrid, np.nan)\n","        PBiaslow = np.full(ngrid, np.nan)\n","        PBiashigh = np.full(ngrid, np.nan)\n","        PBias = np.full(ngrid, np.nan)\n","        PBiasother = np.full(ngrid, np.nan)\n","        KGE = np.full(ngrid, np.nan)\n","        KGE12 = np.full(ngrid, np.nan)\n","        RMSElow = np.full(ngrid, np.nan)\n","        RMSEhigh = np.full(ngrid, np.nan)\n","        RMSEother = np.full(ngrid, np.nan)\n","        for k in range(0, ngrid):\n","            x = pred[k, :]\n","            y = target[k, :]\n","            ind = np.where(np.logical_and(~np.isnan(x), ~np.isnan(y)))[0]\n","            if ind.shape[0] > 0:\n","                xx = x[ind]\n","                yy = y[ind]\n","                # percent bias\n","                PBias[k] = np.sum(xx - yy) / np.sum(yy) * 100\n","\n","                # FHV the peak flows bias 2%\n","                # FLV the low flows bias bottom 30%, log space\n","                pred_sort = np.sort(xx)\n","                target_sort = np.sort(yy)\n","                indexlow = round(0.3 * len(pred_sort))\n","                indexhigh = round(0.98 * len(pred_sort))\n","                lowpred = pred_sort[:indexlow]\n","                highpred = pred_sort[indexhigh:]\n","                otherpred = pred_sort[indexlow:indexhigh]\n","                lowtarget = target_sort[:indexlow]\n","                hightarget = target_sort[indexhigh:]\n","                othertarget = target_sort[indexlow:indexhigh]\n","                PBiaslow[k] = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n","                PBiashigh[k] = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n","                PBiasother[k] = np.sum(otherpred - othertarget) / np.sum(othertarget) * 100\n","                RMSElow[k] = np.sqrt(np.nanmean((lowpred - lowtarget)**2))\n","                RMSEhigh[k] = np.sqrt(np.nanmean((highpred - hightarget)**2))\n","                RMSEother[k] = np.sqrt(np.nanmean((otherpred - othertarget)**2))\n","\n","                if ind.shape[0] > 1:\n","                    # Theoretically at least two points for correlation\n","                    Corr[k] = scipy.stats.pearsonr(xx, yy)[0]\n","                    CorrSp[k] = scipy.stats.spearmanr(xx, yy)[0]\n","                    yymean = yy.mean()\n","                    yystd = np.std(yy)\n","                    xxmean = xx.mean()\n","                    xxstd = np.std(xx)\n","                    KGE[k] = 1 - np.sqrt((Corr[k]-1)**2 + (xxstd/yystd-1)**2 + (xxmean/yymean-1)**2)\n","                    KGE12[k] = 1 - np.sqrt((Corr[k] - 1) ** 2 + ((xxstd*yymean)/ (yystd*xxmean) - 1) ** 2 + (xxmean / yymean - 1) ** 2)\n","                    SST = np.sum((yy-yymean)**2)\n","                    SSReg = np.sum((xx-yymean)**2)\n","                    SSRes = np.sum((yy-xx)**2)\n","                    R2[k] = 1-SSRes/SST\n","                    NSE[k] = 1-SSRes/SST\n","\n","    outDict = dict(Bias=Bias, RMSE=RMSE, ubRMSE=ubRMSE, Corr=Corr, CorrSp=CorrSp, R2=R2, NSE=NSE,\n","                   FLV=PBiaslow, FHV=PBiashigh, PBias=PBias, PBiasother=PBiasother, KGE=KGE, KGE12=KGE12, fdcRMSE=FDCRMSE,\n","                   lowRMSE=RMSElow, highRMSE=RMSEhigh, midRMSE=RMSEother)\n","\n","    return outDict"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":55,"status":"ok","timestamp":1707706634441,"user":{"displayName":"Leo Lonzarich","userId":"03094207546900081501"},"user_tz":360},"id":"uJhJHca9DO_0"},"outputs":[],"source":["def calculate_metrics_multi(args_list, model_outputs, y_obs_list, ensemble_type='max', out_dir=None):\n","    \"\"\"\n","    Calculate stats for a multimodel ensemble.\n","    \"\"\"\n","    stats_list = dict()\n","\n","    for mod in args_list:\n","        args = args_list[mod]\n","        mod_out = model_outputs[mod]\n","        y_obs = y_obs_list[mod]\n","\n","        if mod in ['SACSMA', 'SACSMA_snow', 'marrmot_PRMS', 'HBV']:\n","            # Note for hydrodl HBV, calculations have already been done so skip.\n","\n","            # Saving data\n","            if out_dir:\n","                path = os.path.join(out_dir, 'models', '671_sites_dp', mod)\n","                if not os.path.exists(path):\n","                    os.makedirs(path, exist_ok=True)\n","\n","                # Test data (obs and model results).\n","                for key in mod_out[0].keys():\n","                    if len(mod_out[0][key].shape) == 3:\n","                        dim = 1\n","                    else:\n","                        dim = 0\n","                    concatenated_tensor = torch.cat([d[key] for d in mod_out], dim=dim)\n","                    file_name = key + \".npy\"\n","                    np.save(os.path.join(path, file_name), concatenated_tensor.numpy())\n","                    # np.save(os.path.join(args[\"out_dir\"], args[\"testing_dir\"], file_name), concatenated_tensor.numpy())\n","\n","                # Reading and flow observations.\n","                print(args['target'])\n","                for var in args[\"target\"]:\n","                    item_obs = y_obs[:, :, args[\"target\"].index(var)]\n","                    file_name = var + \".npy\"\n","                    np.save(os.path.join(path, file_name), item_obs)\n","                    # np.save(os.path.join(args[\"out_dir\"], args[\"testing_dir\"], file_name), item_obs)\n","\n","\n","            ###################### calculations here ######################\n","            pred_list = list()\n","            obs_list = list()\n","            flow_sim = torch.cat([d[\"flow_sim\"] for d in mod_out], dim=1)\n","            flow_obs = y_obs[:, :, args[\"target\"].index(\"00060_Mean\")]\n","\n","            pred_list.append(flow_sim.numpy())\n","            obs_list.append(np.expand_dims(flow_obs, 2))\n","            \n","\n","            # we need to swap axes here to have [basin, days], and remove redundant\n","            # dimensions with np.squeeze().\n","            stats_list[mod] = [\n","                statError(np.swapaxes(x.squeeze(), 1, 0), np.swapaxes(y.squeeze(), 1, 0))\n","                for (x, y) in zip(pred_list, obs_list)\n","            ]\n","        elif mod in ['hbvhy', 'dPLHBV_dyn']:\n","            stats_list[mod] = [statError(mod_out[:,:,0], y_obs.squeeze())]\n","        else:\n","            raise ValueError(f\"Unsupported model type in `models`.\")\n","\n","    # Calculating final statistics for the whole set of basins.\n","    name_list = [\"flow\"]\n","    for st, name in zip(stats_list[mod], name_list):\n","        count = 0\n","        mdstd = np.zeros([len(st), 3])\n","        for key in st.keys():\n","            # st contains the statistics on a model run like NSE and KGE.\n","            # Find the best result (e.g., the max, avg, median) and merge from each model.\n","            for i, mod in enumerate(args_list):\n","                if i == 0:\n","                    # temp contains the values of key per basin.\n","                    temp = stats_list[mod][0][key]\n","                    continue\n","                elif i == 1:\n","                    temp = np.stack((temp, stats_list[mod][0][key]), axis=1)\n","                else:\n","                    temp = np.hstack((temp, stats_list[mod][0][key].reshape(-1,1)))\n","            \n","            if len(args_list) > 1:\n","                if ensemble_type == 'max':\n","                    # print(temp, key)\n","                    temp = np.amax(temp, axis=1)\n","                    # print(temp, key)\n","                elif ensemble_type == 'avg':\n","                    temp = np.mean(temp, axis=1)\n","                elif ensemble_type == 'median':\n","                    temp = np.median(temp, axis=1)\n","                elif ensemble_type == 'softmax':\n","                    # # Softmax gets relative contributions of each model.\n","                    # weights = torch.nn.functional.softmax(torch.from_numpy(temp), dim=1)\n","                    # temp = np.sum(temp * weights.numpy(), axis=1)\n","\n","                    # Instantiate weighting lstm with softmax.\n","                    lstm = hydroEnsemble(num_models=len(args_list), hidden_size=192, num_layers=3)\n","                    # Forward pass through the model\n","                    temp = lstm(torch.tensor(temp, dtype=torch.float))\n","                else:\n","                    raise ValueError(\"Invalid model ensemble type specified.\")\n","\n","            median = np.nanmedian(temp)  # abs(i)\n","            std = np.nanstd(temp)  # abs(i)\n","            mean = np.nanmean(temp)  # abs(i)\n","            k = np.array([[median, std, mean]])\n","            mdstd[count] = k\n","            count = count + 1\n","\n","        # mdstd displays the statistics for each error measure in stats_list.\n","        mdstd = pd.DataFrame(\n","            mdstd, index=st.keys(), columns=[\"median\", \"STD\", \"mean\"]\n","        )\n","        # Save the data stats from the training run:\n","        if out_dir and len(args_list) > 1:\n","            path = os.path.join(out_dir, 'multimodels', '671_sites_dp', 'n_' + ensemble_type)\n","            if not os.path.exists(path):\n","                os.makedirs(path, exist_ok=True)\n","\n","            mdstd.to_csv((os.path.join(path, \"mdstd_\" + name + \"_\" + ensemble_type +\".csv\")))\n","        elif out_dir:\n","            path = os.path.join(out_dir, 'models', '671_sites_dp', args_list[0])\n","            if not os.path.exists(path):\n","                os.makedirs(path, exist_ok=True)\n","\n","            mdstd.to_csv((os.path.join(path, \"mdstd_\" + name + \"_\" + \".csv\")))\n","        else: continue\n","\n","    # Show boxplots of the results\n","    # plt.rcParams[\"font.size\"] = 14\n","    # keyLst = [\"Bias\", \"RMSE\", \"ubRMSE\", \"NSE\", \"Corr\"]\n","    # dataBox = list()\n","    # for iS in range(len(keyLst)):\n","    #     statStr = keyLst[iS]\n","    #     temp = list()\n","    #     # for k in range(len(st)):\n","    #     data = st[statStr]\n","    #     data = data[~np.isnan(data)]\n","    #     temp.append(data)\n","    #     dataBox.append(temp)\n","    # labelname = [\n","    #     \"Hybrid differentiable model\"\n","    # ]  # ['STA:316,batch158', 'STA:156,batch156', 'STA:1032,batch516']   # ['LSTM-34 Basin']\n","\n","    # xlabel = [\"Bias ($\\mathregular{deg}$C)\", \"RMSE\", \"ubRMSE\", \"NSE\", \"Corr\"]\n","    # fig = plot.plotBoxFig(\n","    #     dataBox, xlabel, label2=labelname, sharey=False, figsize=(16, 8)\n","    # )\n","    # fig.patch.set_facecolor(\"white\")\n","    # boxPlotName = \"PGML\"\n","    # fig.suptitle(boxPlotName, fontsize=12)\n","    # plt.rcParams[\"font.size\"] = 12\n","    # # plt.savefig(\n","    # #     os.path.join(args[\"out_dir\"], args[\"testing_dir\"], \"Box_\" + name + \".png\")\n","    # # )  # , dpi=500\n","    # # fig.show()\n","    # plt.close()\n","\n","    torch.cuda.empty_cache()\n","    print(\"Testing ended\")\n","\n","    return stats_list, mdstd\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","### Multimodel wrapper internals:\n","---"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["args_list = {'dPLHBV_dyn': hbvhyArgs_d, 'SACSMA_snow':sacsmaSnowArgs, 'marrmot_PRMS':prmsArgs}   # 'hbvhy': hbvhyArgs, 'HBV' : hbvArgs, 'SACSMA_snow':None, 'SACSMA': sacsmaArgs,\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dPLHBV_dyn\n","SACSMA_snow\n","marrmot_PRMS\n"]}],"source":["# Initialize\n","flow_preds = []\n","flow_obs = None\n","obs_trig = False\n","\n","# Concatenate individual model predictions, and observation data.\n","for i, mod in enumerate(args_list):\n","    args = args_list[mod]\n","    mod_out = model_output[mod]\n","    y_ob = y_obs[mod]\n","\n","    print(mod)\n","\n","    if mod in ['HBV', 'SACSMA', 'SACSMA_snow', 'marrmot_PRMS']:\n","        # Hydro models are tested in batches, so we concatenate them and select\n","        # the desired flow.\n","        # Note: modified HBV already has this preparation done during testing.\n","\n","        # Get flow predictions and swap axes to get shape [basins, days]\n","        pred = np.swapaxes(torch.cat([d[\"flow_sim\"] for d in mod_out], dim=1).squeeze().numpy(), 0, 1)\n","\n","        if obs_trig == False:\n","            # dPLHBV uses GAGES while the other hydro models use CAMELS data. This means small \n","            # e-5 variation in observation data between the two. This is averaged if both models\n","            # are used, but to avoid double-counting data from multiply hydro models, use a trigger.\n","            obs = np.swapaxes(y_ob[:, :, args[\"target\"].index(\"00060_Mean\")].numpy(), 0, 1)\n","            obs_trig = True\n","            dup = False\n","        else:\n","            dup = True\n","\n","    elif mod in ['dPLHBV_dyn']:\n","        pred = mod_out[:,:,0][:,365:] # Set dim2 = 0 to get streamflow Qr\n","        obs = y_ob.squeeze()[:,365:]\n","        dup = False\n","\n","    else:\n","        raise ValueError(f\"Unsupported model type in `models`.\")\n","    \n","    if i == 0:\n","        tmp_pred = pred\n","        tmp_obs = obs\n","    elif i == 1:\n","        tmp_pred = np.stack((tmp_pred, pred), axis=2)\n","        if not dup:\n","            # Avoid double-counting GAGES obs.\n","            tmp_obs = np.stack((tmp_obs, obs), axis=2)\n","    else:\n","        # Combine outputs of >3 models.\n","        tmp_pred = np.concatenate((tmp_pred,np.expand_dims(pred, 2)), axis=2)\n","        if not dup:\n","            # Avoid double-counting GAGES obs.\n","            tmp_obs = np.concatenate((tmp_obs,np.expand_dims(obs, 2)), axis=2)\n","\n","preds = tmp_pred\n","obs = tmp_obs"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["ensemble_type = 'min'\n","\n","# Merge model predictions using specified merging type.\n","if len(preds.shape) == 3:\n","    if ensemble_type == 'max':\n","        comp_preds = np.amax(preds, axis=2)\n","    elif ensemble_type == 'min':\n","        comp_preds = np.amin(preds, axis=2)\n","    elif ensemble_type == 'avg':\n","        comp_preds = np.mean(preds, axis=2)\n","    elif ensemble_type == 'median':\n","        comp_preds = np.median(preds, axis=2)\n","    elif ensemble_type == 'softmax':\n","        pass\n","        ########### IN PROGRESS ############\n","        ####################################\n","    else:\n","        raise ValueError(\"Invalid model ensemble type specified.\")\n","elif len(preds.shape) == 2:\n","    pass  # For single model, do nothing\n","else:\n","    raise ValueError(\"Error reading prediction data: incorrect formatting.\")\n","\n","# Merge observation data.\n","if len(obs.shape) == 3:\n","    comp_obs = np.mean(obs, axis = 2)\n","elif len(obs.shape) == 2:\n","    comp_obs = obs\n","else:\n","    raise ValueError(\"Error reading prediction data: incorrect formatting.\")\n"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing ended\n"]}],"source":["# Calculating performance statistics at each basin e.g., NSE, KGE.\n","stat = statError(comp_preds, comp_obs)\n","\n","mdstd = np.zeros([len(stat), 3])\n","count = 0\n","\n","# Find median statistics across all basins.\n","for key in stat.keys():\n","    temp = stat[key]\n","    median = np.nanmedian(temp)\n","    std = np.nanstd(temp)\n","    mean = np.nanmean(temp)\n","\n","    k = np.array([[median, std, mean]])\n","    mdstd[count] = k\n","    count = count + 1\n","\n","    \n","# mdstd gives the statistics for each error measure in stats_list.\n","mdstd = pd.DataFrame(\n","    mdstd, index=stat.keys(), columns=[\"median\", \"STD\", \"mean\"]\n",")\n","    \n","\n","torch.cuda.empty_cache()\n","print(\"Testing ended\")\n"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>median</th>\n","      <th>STD</th>\n","      <th>mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Bias</th>\n","      <td>-0.128361</td>\n","      <td>0.396119</td>\n","      <td>-0.233229</td>\n","    </tr>\n","    <tr>\n","      <th>RMSE</th>\n","      <td>1.112858</td>\n","      <td>1.084886</td>\n","      <td>1.337561</td>\n","    </tr>\n","    <tr>\n","      <th>ubRMSE</th>\n","      <td>1.090025</td>\n","      <td>1.030170</td>\n","      <td>1.301342</td>\n","    </tr>\n","    <tr>\n","      <th>Corr</th>\n","      <td>0.866736</td>\n","      <td>0.124928</td>\n","      <td>0.826612</td>\n","    </tr>\n","    <tr>\n","      <th>CorrSp</th>\n","      <td>0.851400</td>\n","      <td>0.108794</td>\n","      <td>0.826104</td>\n","    </tr>\n","    <tr>\n","      <th>R2</th>\n","      <td>0.716465</td>\n","      <td>0.245980</td>\n","      <td>0.643191</td>\n","    </tr>\n","    <tr>\n","      <th>NSE</th>\n","      <td>0.716465</td>\n","      <td>0.245980</td>\n","      <td>0.643191</td>\n","    </tr>\n","    <tr>\n","      <th>FLV</th>\n","      <td>-8.217311</td>\n","      <td>NaN</td>\n","      <td>inf</td>\n","    </tr>\n","    <tr>\n","      <th>FHV</th>\n","      <td>-18.342615</td>\n","      <td>20.927495</td>\n","      <td>-21.580557</td>\n","    </tr>\n","    <tr>\n","      <th>PBias</th>\n","      <td>-15.461230</td>\n","      <td>19.694802</td>\n","      <td>-18.198053</td>\n","    </tr>\n","    <tr>\n","      <th>PBiasother</th>\n","      <td>-14.815078</td>\n","      <td>389.884750</td>\n","      <td>-1.569876</td>\n","    </tr>\n","    <tr>\n","      <th>KGE</th>\n","      <td>0.687255</td>\n","      <td>0.258623</td>\n","      <td>0.615414</td>\n","    </tr>\n","    <tr>\n","      <th>KGE12</th>\n","      <td>0.741293</td>\n","      <td>0.229454</td>\n","      <td>0.672415</td>\n","    </tr>\n","    <tr>\n","      <th>fdcRMSE</th>\n","      <td>1.055918</td>\n","      <td>2.997112</td>\n","      <td>2.019323</td>\n","    </tr>\n","    <tr>\n","      <th>lowRMSE</th>\n","      <td>0.043183</td>\n","      <td>0.168497</td>\n","      <td>0.085248</td>\n","    </tr>\n","    <tr>\n","      <th>highRMSE</th>\n","      <td>3.108262</td>\n","      <td>4.953427</td>\n","      <td>4.420479</td>\n","    </tr>\n","    <tr>\n","      <th>midRMSE</th>\n","      <td>0.260378</td>\n","      <td>0.528939</td>\n","      <td>0.414988</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               median         STD       mean\n","Bias        -0.128361    0.396119  -0.233229\n","RMSE         1.112858    1.084886   1.337561\n","ubRMSE       1.090025    1.030170   1.301342\n","Corr         0.866736    0.124928   0.826612\n","CorrSp       0.851400    0.108794   0.826104\n","R2           0.716465    0.245980   0.643191\n","NSE          0.716465    0.245980   0.643191\n","FLV         -8.217311         NaN        inf\n","FHV        -18.342615   20.927495 -21.580557\n","PBias      -15.461230   19.694802 -18.198053\n","PBiasother -14.815078  389.884750  -1.569876\n","KGE          0.687255    0.258623   0.615414\n","KGE12        0.741293    0.229454   0.672415\n","fdcRMSE      1.055918    2.997112   2.019323\n","lowRMSE      0.043183    0.168497   0.085248\n","highRMSE     3.108262    4.953427   4.420479\n","midRMSE      0.260378    0.528939   0.414988"]},"execution_count":177,"metadata":{},"output_type":"execute_result"}],"source":["mdstd"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>median</th>\n","      <th>STD</th>\n","      <th>mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Bias</th>\n","      <td>0.023718</td>\n","      <td>0.324475</td>\n","      <td>-0.007196</td>\n","    </tr>\n","    <tr>\n","      <th>RMSE</th>\n","      <td>1.083596</td>\n","      <td>1.033153</td>\n","      <td>1.294601</td>\n","    </tr>\n","    <tr>\n","      <th>ubRMSE</th>\n","      <td>1.071202</td>\n","      <td>1.004565</td>\n","      <td>1.276288</td>\n","    </tr>\n","    <tr>\n","      <th>Corr</th>\n","      <td>0.871354</td>\n","      <td>0.113781</td>\n","      <td>0.836386</td>\n","    </tr>\n","    <tr>\n","      <th>CorrSp</th>\n","      <td>0.869448</td>\n","      <td>0.098403</td>\n","      <td>0.846168</td>\n","    </tr>\n","    <tr>\n","      <th>R2</th>\n","      <td>0.736110</td>\n","      <td>0.316586</td>\n","      <td>0.644530</td>\n","    </tr>\n","    <tr>\n","      <th>NSE</th>\n","      <td>0.736110</td>\n","      <td>0.316586</td>\n","      <td>0.644530</td>\n","    </tr>\n","    <tr>\n","      <th>FLV</th>\n","      <td>51.805849</td>\n","      <td>NaN</td>\n","      <td>inf</td>\n","    </tr>\n","    <tr>\n","      <th>FHV</th>\n","      <td>-8.080002</td>\n","      <td>23.566628</td>\n","      <td>-8.479628</td>\n","    </tr>\n","    <tr>\n","      <th>PBias</th>\n","      <td>3.038742</td>\n","      <td>22.696646</td>\n","      <td>3.172665</td>\n","    </tr>\n","    <tr>\n","      <th>PBiasother</th>\n","      <td>5.208965</td>\n","      <td>888.020392</td>\n","      <td>42.463733</td>\n","    </tr>\n","    <tr>\n","      <th>KGE</th>\n","      <td>0.757558</td>\n","      <td>0.238962</td>\n","      <td>0.680079</td>\n","    </tr>\n","    <tr>\n","      <th>KGE12</th>\n","      <td>0.758027</td>\n","      <td>0.214380</td>\n","      <td>0.690648</td>\n","    </tr>\n","    <tr>\n","      <th>fdcRMSE</th>\n","      <td>0.915600</td>\n","      <td>2.854887</td>\n","      <td>1.784917</td>\n","    </tr>\n","    <tr>\n","      <th>lowRMSE</th>\n","      <td>0.074085</td>\n","      <td>0.136543</td>\n","      <td>0.105348</td>\n","    </tr>\n","    <tr>\n","      <th>highRMSE</th>\n","      <td>2.416864</td>\n","      <td>4.543003</td>\n","      <td>3.695367</td>\n","    </tr>\n","    <tr>\n","      <th>midRMSE</th>\n","      <td>0.211841</td>\n","      <td>0.400107</td>\n","      <td>0.311744</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               median         STD       mean\n","Bias         0.023718    0.324475  -0.007196\n","RMSE         1.083596    1.033153   1.294601\n","ubRMSE       1.071202    1.004565   1.276288\n","Corr         0.871354    0.113781   0.836386\n","CorrSp       0.869448    0.098403   0.846168\n","R2           0.736110    0.316586   0.644530\n","NSE          0.736110    0.316586   0.644530\n","FLV         51.805849         NaN        inf\n","FHV         -8.080002   23.566628  -8.479628\n","PBias        3.038742   22.696646   3.172665\n","PBiasother   5.208965  888.020392  42.463733\n","KGE          0.757558    0.238962   0.680079\n","KGE12        0.758027    0.214380   0.690648\n","fdcRMSE      0.915600    2.854887   1.784917\n","lowRMSE      0.074085    0.136543   0.105348\n","highRMSE     2.416864    4.543003   3.695367\n","midRMSE      0.211841    0.400107   0.311744"]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["mdstd"]},{"cell_type":"markdown","metadata":{},"source":["---\n","### Naive model wrapper\n","---"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":126,"status":"ok","timestamp":1707706633957,"user":{"displayName":"Leo Lonzarich","userId":"03094207546900081501"},"user_tz":360},"id":"RtdVYl00DO_z"},"outputs":[],"source":["class hydroEnsemble(torch.nn.Module):\n","    # Wrapper for multiple hydrologic models.\n","    # In future, consider just passing the models you want to ensemble explicitly.\n","    def __init__(self, num_models, hidden_size, num_layers):\n","        super(hydroEnsemble, self).__init__()\n","\n","        self.lstm = torch.nn.LSTM(num_models, hidden_size, num_layers, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_size, num_models)  # Two models (modelA and modelB)\n","\n","        # self.modelA = modelA\n","        # self.modelB = modelB\n","        # self.classifier = torch.nn.Linear(4, 2)\n","\n","    def forward(self, x):\n","        # x is the input sequence tensor with shape (batch_size, sequence_length, num_models)\n","\n","        # Setting randomseed for deterministic output.\n","        randomseed_config(0)\n","\n","        # Add batch dimension to input and convert to tensor.\n","        x_exp = x.unsqueeze(0)\n","\n","        # LSTM layer\n","        lstm_out, _ = self.lstm(x_exp)\n","\n","        # Fully connected layer\n","        fc_out = self.fc(lstm_out)\n","\n","        # Apply softmax activation to obtain weights\n","        weights = torch.nn.functional.softmax(fc_out, dim=2).squeeze()\n","\n","        # Weighted combination of predictions.\n","        weighted_preds = np.multiply(weights.detach(), x)\n","\n","        # Or take the max weight and return the corresponding value.\n","        max_vals, _ = torch.max(weights, dim=1)\n","        btensor = torch.zeros_like(weights)\n","        btensor[weights==max_vals.view(-1,1)] = 1\n","        weighted_preds = np.multiply(btensor.detach(), x)\n","\n","        preds = torch.sum(weighted_preds, dim=1)\n","\n","        # All tensors\n","        # return preds, weights, weighted_preds\n","        return preds\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["args_list = {'dPLHBV_dyn': hbvhyArgs_d}   # 'hbvhy': hbvhyArgs, 'HBV' : hbvArgs, 'SACSMA_snow':None, 'SACSMA': sacsmaArgs,"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"LSTM: Expected input to be 2D or 3D, got 4D instead","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m lstm \u001b[38;5;241m=\u001b[39m hydroEnsemble(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(args_list), hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m192\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/PGML_STemp/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/PGML_STemp/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[22], line 24\u001b[0m, in \u001b[0;36mhydroEnsemble.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m x_exp \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# LSTM layer\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_exp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Fully connected layer\u001b[39;00m\n\u001b[1;32m     27\u001b[0m fc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/PGML_STemp/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/PGML_STemp/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/PGML_STemp/lib/python3.12/site-packages/torch/nn/modules/rnn.py:844\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 844\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    845\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    846\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 4D instead"]}],"source":["# # Softmax gets relative contributions of each model.\n","# weights = torch.nn.functional.softmax(torch.from_numpy(temp), dim=1)\n","# temp = np.sum(temp * weights.numpy(), axis=1)\n","\n","# Instantiate weighting lstm with softmax.\n","lstm = hydroEnsemble(num_models=len(args_list), hidden_size=192, num_layers=3)\n","# Forward pass through the model\n","lstm(torch.tensor(preds, dtype=torch.float))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
