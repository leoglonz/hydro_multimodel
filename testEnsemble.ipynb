{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting ensemble code of Farshid 2023\n",
    "*Requires cuda\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2Model(model,\n",
    "                loaded_hbv,\n",
    "               x,\n",
    "                x2,\n",
    "               y,\n",
    "               c,\n",
    "                c2,\n",
    "               lossFun,\n",
    "               *,\n",
    "               nEpoch=500,\n",
    "               miniBatch=[100, 30],\n",
    "               saveEpoch=100,\n",
    "               saveFolder=None,\n",
    "               mode='seq2seq',\n",
    "               bufftime=0,\n",
    "               prcp_loss_factor = 15,\n",
    "               smooth_loss_factor = 0,\n",
    "               multiforcing=False):\n",
    "    batchSize, rho = miniBatch\n",
    "    # x- input; z - additional input; y - target; c - constant input\n",
    "    if type(x) is tuple or type(x) is list:\n",
    "        x, z = x\n",
    "        x2, z2 = x2\n",
    "    ngrid, nt, nx = x.shape\n",
    "    ngrid, nt, nx2 = x2.shape\n",
    "    if c is not None:\n",
    "        nx = nx + c.shape[-1]\n",
    "        nx2 = nx2 + c2.shape[-1]\n",
    "    if batchSize >= ngrid:\n",
    "        # batchsize larger than total grids\n",
    "        batchSize = ngrid\n",
    "\n",
    "    nIterEp = int(\n",
    "        np.ceil(np.log(0.01) / np.log(1 - batchSize * rho / ngrid / (nt-bufftime))))\n",
    "    if hasattr(model, 'ctRm'):\n",
    "        if model.ctRm is True:\n",
    "            nIterEp = int(\n",
    "                np.ceil(\n",
    "                    np.log(0.01) / np.log(1 - batchSize *\n",
    "                                          (rho - model.ct) / ngrid / (nt-bufftime))))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        lossFun = lossFun.cuda()\n",
    "        model = model.cuda()\n",
    "        # loaded_hbv = loaded_hbv.cuda()\n",
    "\n",
    "    # optim = torch.optim.Adadelta(list(model.parameters()) + list(loaded_hbv.parameters()))\n",
    "    optim = torch.optim.Adadelta(list(model.parameters()))\n",
    "    # loaded_hbv.zero_grad()\n",
    "    model.zero_grad()\n",
    "    if saveFolder is not None:\n",
    "        runFile = os.path.join(saveFolder, 'run.csv')\n",
    "        rf = open(runFile, 'w+')\n",
    "    for iEpoch in range(1, nEpoch + 1):\n",
    "        lossEp = 0\n",
    "        if multiforcing is True:\n",
    "            loss_prcp_Ep = 0\n",
    "            # loss_pet_Ep = 0\n",
    "            # loss_temp_Ep = 0\n",
    "            loss_sf_Ep = 0\n",
    "            # loss_smooth_Ep = 0\n",
    "        t0 = time.time()\n",
    "        for iIter in range(0, nIterEp):\n",
    "            # training iterations\n",
    "            if type(model) in [rnn.LstmCloseModel, rnn.AnnCloseModel, rnn.CNN1dLSTMmodel, rnn.CNN1dLSTMInmodel,\n",
    "                               rnn.CNN1dLCmodel, rnn.CNN1dLCInmodel, rnn.CudnnInvLstmModel,\n",
    "                               rnn.MultiInv_HBVModel, rnn.MultiInv_HBVTDModel, rnn.prcp_weights]:\n",
    "                iGrid, iT = randomIndex(ngrid, nt, [batchSize, rho], bufftime=bufftime)\n",
    "                if type(model) in [rnn.MultiInv_HBVModel, rnn.MultiInv_HBVTDModel, rnn.prcp_weights]:\n",
    "                    xTrain = selectSubset(x, iGrid, iT, rho, bufftime=bufftime)\n",
    "                    xTrain_hbv = selectSubset(x2, iGrid, iT, rho, bufftime=bufftime)\n",
    "                else:\n",
    "                    xTrain = selectSubset(x, iGrid, iT, rho, c=c)\n",
    "                    xTrain_hbv = selectSubset(x2, iGrid, iT, rho, c=c2)\n",
    "                yTrain = selectSubset(y, iGrid, iT, rho)\n",
    "                if type(model) in [rnn.CNN1dLCmodel, rnn.CNN1dLCInmodel]:\n",
    "                    zTrain = selectSubset(z, iGrid, iT=None, rho=None, LCopt=True)\n",
    "                    zTrain_hbv = selectSubset(z2, iGrid, iT=None, rho=None, LCopt=True)\n",
    "                elif type(model) in [rnn.CudnnInvLstmModel]: # For smap inv LSTM, HBV Inv\n",
    "                    # zTrain = selectSubset(z, iGrid, iT=None, rho=None, LCopt=False)\n",
    "                    zTrain = selectSubset(z, iGrid, iT=None, rho=None, LCopt=False, c=c) # Add the attributes to inv\n",
    "                    zTrain_hbv = selectSubset(z2, iGrid, iT=None, rho=None, LCopt=False, c=c2) # Add the attributes to inv\n",
    "                elif type(model) in [rnn.MultiInv_HBVModel]:\n",
    "                    zTrain = selectSubset(z, iGrid, iT, rho, c=c)\n",
    "                    zTrain_hbv = selectSubset(z2, iGrid, iT, rho, c=c2)\n",
    "                elif type(model) in [rnn.MultiInv_HBVTDModel, rnn.prcp_weights]:\n",
    "                    zTrain = selectSubset(z, iGrid, iT, rho, c=c, bufftime=bufftime)\n",
    "                    zTrain_hbv = selectSubset(z2, iGrid, iT, rho, c=c2, bufftime=bufftime)\n",
    "                else:\n",
    "                    zTrain = selectSubset(z, iGrid, iT, rho)\n",
    "                    zTrain_hbv = selectSubset(z2, iGrid, iT, rho)\n",
    "                # loaded_hbv.train(mode=False)\n",
    "                    \n",
    "                    \n",
    "                xP, prcp_loss, prcp_wghts = model(xTrain, zTrain, prcp_loss_factor)\n",
    "                yP = loaded_hbv(xP, zTrain_hbv, prcp_loss_factor =0, smooth_loss_factor=0, multiforcing=False)\n",
    "                # yP = model(xTrain, zTrain, prcp_loss_factor, smooth_loss_factor, multiforcing)\n",
    "                # yP = model(xTrain, zTrain)\n",
    "            if type(model) in [cnn.LstmCnn1d]:\n",
    "                iGrid, iT = randomIndex(ngrid, nt, [batchSize, rho])\n",
    "                xTrain = selectSubset(x, iGrid, iT, rho, c=c)\n",
    "                # xTrain = rho/time * Batchsize * Ninput_var\n",
    "                xTrain = xTrain.permute(1, 2, 0)\n",
    "                yTrain = selectSubset(y, iGrid, iT, rho)\n",
    "                # yTrain = rho/time * Batchsize * Ntraget_var\n",
    "                yTrain = yTrain.permute(1, 2, 0)[:, :, int(rho/2):]\n",
    "                yP = model(xTrain)\n",
    "            # if type(model) in [hydroDL.model.rnn.LstmCnnCond]:\n",
    "            #     iGrid, iT = randomIndex(ngrid, nt, [batchSize, rho])\n",
    "            #     xTrain = selectSubset(x, iGrid, iT, rho)\n",
    "            #     yTrain = selectSubset(y, iGrid, iT, rho)\n",
    "            #     zTrain = selectSubset(z, iGrid, None, None)\n",
    "            #     yP = model(xTrain, zTrain)\n",
    "            # if type(model) in [hydroDL.model.rnn.LstmCnnForcast]:\n",
    "            #     iGrid, iT = randomIndex(ngrid, nt, [batchSize, rho])\n",
    "            #     xTrain = selectSubset(x, iGrid, iT, rho)\n",
    "            #     yTrain = selectSubset(y, iGrid, iT + model.ct, rho - model.ct)\n",
    "            #     zTrain = selectSubset(z, iGrid, iT, rho)\n",
    "            #     yP = model(xTrain, zTrain)\n",
    "            else:\n",
    "                Exception('unknown model')\n",
    "            # # consider the buff time for initialization\n",
    "            # if bufftime > 0:\n",
    "            #     yP = yP[bufftime:,:,:]\n",
    "            ## temporary test for NSE loss\n",
    "            if type(lossFun) in [crit.NSELossBatch, crit.NSESqrtLossBatch]:\n",
    "                # if multiforcing==True:\n",
    "                loss_sf = lossFun(yP, yTrain, iGrid)\n",
    "                loss =  loss_sf + prcp_loss\n",
    "                # else:\n",
    "                #     loss = lossFun(yP, yTrain, iGrid)\n",
    "            else:\n",
    "                # if multiforcing==True:\n",
    "                loss_sf = lossFun(yP, yTrain)\n",
    "                loss = loss_sf + prcp_loss\n",
    "                # else:\n",
    "                #     loss = lossFun(yP, yTrain)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            # model.zero_grad()\n",
    "            optim.zero_grad()\n",
    "            lossEp = lossEp + loss.item()\n",
    "            try:\n",
    "                loss_prcp_Ep = loss_prcp_Ep + prcp_loss.item()\n",
    "            except:\n",
    "                pass\n",
    "            # loss_pet_Ep = loss_pet_Ep + pet_loss.item()\n",
    "            # loss_temp_Ep = loss_temp_Ep + temp_loss.item()\n",
    "            # loss_temp_Ep = 0\n",
    "            # loss_pet_Ep = 0\n",
    "            loss_sf_Ep = loss_sf_Ep + loss_sf.item()\n",
    "                # loss_smooth_Ep = loss_smooth_Ep + smooth_loss.item()\n",
    "            # print(iIter, '  ', loss.item())\n",
    "            # if iIter == 223:\n",
    "            #     print('This is the error point')\n",
    "            #     print('Debug start')\n",
    "\n",
    "            if iIter % 100 == 0:\n",
    "                print('Iter {} of {}: Loss {:.3f}'.format(iIter, nIterEp, loss.item()))\n",
    "        # print loss\n",
    "        lossEp = lossEp / nIterEp\n",
    "        # if multiforcing==True:\n",
    "        loss_sf_Ep = loss_sf_Ep / nIterEp\n",
    "        loss_prcp_Ep = loss_prcp_Ep / nIterEp\n",
    "        # loss_pet_Ep = loss_pet_Ep / nIterEp\n",
    "        # loss_temp_Ep = loss_temp_Ep / nIterEp\n",
    "        logStr = 'Epoch {} Loss {:.3f}, Streamflow Loss {:.3f}, Precipitation Loss {:.3f}, time {:.2f}'.format(\n",
    "            iEpoch, lossEp, loss_sf_Ep, loss_prcp_Ep,\n",
    "            time.time() - t0)\n",
    "        # else:\n",
    "        #     logStr = 'Epoch {} Loss {:.3f}, time {:.2f}'.format(\n",
    "        #         iEpoch, lossEp, time.time() - t0)\n",
    "        print(logStr)\n",
    "        # save model and loss\n",
    "        if saveFolder is not None:\n",
    "            rf.write(logStr + '\\n')\n",
    "            if iEpoch % saveEpoch == 0:\n",
    "                # save model\n",
    "                modelFile = os.path.join(saveFolder,\n",
    "                                         'model_Ep' + str(iEpoch) + '.pt')\n",
    "                torch.save(model, modelFile)\n",
    "                # modelFile_hbv = os.path.join(saveFolder,\n",
    "                #                          'model_hbv_Ep' + str(iEpoch) + '.pt')\n",
    "                # torch.save(loaded_hbv, modelFile_hbv)\n",
    "    if saveFolder is not None:\n",
    "        rf.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all of the train2lstm_3.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prcp_weights(torch.nn.Module):\n",
    "    def __init__(self, *, ninv, hiddeninv, drinv=0.5, prcp_datatypes=1):\n",
    "        super(prcp_weights, self).__init__()\n",
    "        self.ninv = ninv\n",
    "        self.prcp_datatypes = prcp_datatypes\n",
    "\n",
    "        ntp = prcp_datatypes*3\n",
    "        self.hiddeninv = hiddeninv\n",
    "\n",
    "        self.lstminv = CudnnLstmModel(\n",
    "            nx=ninv, ny=ntp, hiddenSize=hiddeninv, dr=drinv)\n",
    "        lb_prcp = [0.95]\n",
    "        ub_prcp = [1.05]\n",
    "        self.RangeBoundLoss = RangeBoundLoss(lb=lb_prcp, ub=ub_prcp)\n",
    "\n",
    "    def forward(self, x, z, prcp_loss_factor):\n",
    "        z.requires_grad = True\n",
    "\n",
    "        wghts = self.lstminv(z)\n",
    "        ntstep = wghts.shape[0]\n",
    "        ngage = wghts.shape[1]\n",
    "        wghts_scaled = torch.sigmoid(wghts)\n",
    "        prcp_wavg = torch.zeros((ntstep, ngage), requires_grad=True, dtype=torch.float32).cuda()\n",
    "        # prcp_wghts_sum = torch.sum(wghts_scaled, dim=2)\n",
    "\n",
    "\n",
    "        temp_wavg = torch.zeros((ntstep, ngage), requires_grad=True, dtype=torch.float32).cuda()\n",
    "        pet_wavg = torch.zeros((ntstep, ngage), requires_grad=True, dtype=torch.float32).cuda()\n",
    "        prcp_wghts_sum = torch.sum(wghts_scaled[:,:,:3], dim=2)\n",
    "        temp_wghts_sum = torch.sum(wghts_scaled[:,:,3:6], dim=2)\n",
    "        pet_wghts_sum = torch.sum(wghts_scaled[:,:,6:], dim=2)\n",
    "\n",
    "\n",
    "\n",
    "        for para in range(wghts.shape[2]):\n",
    "            if para<3:\n",
    "                prcp_wavg = prcp_wavg + wghts_scaled[:, :, para] * x[:, :, para]\n",
    "            elif para<6:\n",
    "                temp_wavg = temp_wavg + wghts_scaled[:, :, para] * x[:, :, para]\n",
    "            elif para>=6:\n",
    "                pet_wavg = pet_wavg + wghts_scaled[:, :, para] * x[:, :, para]\n",
    "\n",
    "        x_new = torch.empty((ntstep, ngage, 3), requires_grad=True, dtype=torch.float32).cuda()\n",
    "        x_new[:, :, 0] = prcp_wavg\n",
    "        # x_new[:, :, 1] = x[:, :, self.prcp_datatypes]\n",
    "        # x_new[:, :, 2] = x[:, :, -1]\n",
    "        x_new[:, :, 1] = temp_wavg\n",
    "        x_new[:, :, 2] = pet_wavg\n",
    "        # range_bound_loss_prcp = self.RangeBoundLoss([prcp_wghts_sum], factor=prcp_loss_factor)+self.RangeBoundLoss([temp_wghts_sum], factor=prcp_loss_factor)+self.RangeBoundLoss([pet_wghts_sum], factor=prcp_loss_factor)\n",
    "        range_bound_loss_prcp = self.RangeBoundLoss([prcp_wghts_sum], factor=prcp_loss_factor)\n",
    "\n",
    "        # range_bound_loss_prcp = 0\n",
    "\n",
    "        grad_daymet = autograd.grad(outputs=wghts_scaled[:, :, 0], inputs=z, grad_outputs=torch.ones_like(wghts_scaled[:, :, 0]), retain_graph=True)[0]\n",
    "        grad_maurer = autograd.grad(outputs=wghts_scaled[:, :, 1], inputs=z, grad_outputs=torch.ones_like(wghts_scaled[:, :, 1]), retain_graph=True)[0]\n",
    "        grad_nldas = autograd.grad(outputs=wghts_scaled[:, :, 2], inputs=z, grad_outputs=torch.ones_like(wghts_scaled[:, :, 2]), retain_graph=True)[0]\n",
    "\n",
    "        return x_new, range_bound_loss_prcp, wghts_scaled, grad_daymet, grad_maurer, grad_nldas\n",
    "        # return x_new, range_bound_loss_prcp, wghts_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_weights"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
