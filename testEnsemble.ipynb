{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting ensemble code of Kamlesh 2023\n",
    "*Requires cuda\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dPLHBV_dyn\n",
      "SACSMA_snow\n",
      "marrmot_PRMS\n"
     ]
    }
   ],
   "source": [
    "from config.read_configurations import config_hbv as hbvArgs\n",
    "from config.read_configurations import config_prms as prmsArgs\n",
    "from config.read_configurations import config_sacsma as sacsmaArgs\n",
    "from config.read_configurations import config_sacsma_snow as sacsmaSnowArgs\n",
    "from config.read_configurations import config_hbv_hydrodl as hbvhyArgs_d\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "# from post import plot\n",
    "\n",
    "from core.utils.randomseed_config import randomseed_config\n",
    "from core.utils.master import create_output_dirs\n",
    "from MODELS.loss_functions.get_loss_function import get_lossFun\n",
    "from MODELS.test_dp_HBV_dynamic import test_dp_hbv\n",
    "from core.data_processing.data_loading import loadData\n",
    "from core.data_processing.normalization import transNorm\n",
    "from core.utils.randomseed_config import randomseed_config\n",
    "from core.data_processing.model import (\n",
    "    take_sample_test,\n",
    "    converting_flow_from_ft3_per_sec_to_mm_per_day\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Set path to `hydro_multimodel_results` directory.\n",
    "if platform.system() == 'Darwin':\n",
    "    # For mac os\n",
    "    out_dir = '/Users/leoglonz/Desktop/water/data/model_runs/hydro_multimodel_results'\n",
    "    # Some operations are not yet working with MPS, so we might need to set some environment variables to use CPU fall instead\n",
    "    # %env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "elif platform.system() == 'Windows':\n",
    "    # For windows\n",
    "    out_dir = 'D:\\\\data\\\\model_runs\\\\hydro_multimodel_results\\\\'\n",
    "\n",
    "elif platform.system() == 'Linux':\n",
    "    # For Colab\n",
    "    out_dir = '/content/drive/MyDrive/Colab/data/model_runs/hydro_multimodel_results'\n",
    "\n",
    "else:\n",
    "    raise ValueError('Unsupported operating system.')\n",
    "\n",
    "\n",
    "##-----## Multi-model Parameters ##-----##\n",
    "##--------------------------------------##\n",
    "# Setting dictionaries to separately manage each diff model's attributes.\n",
    "models = {'dPLHBV_dyn': None, 'SACSMA_snow':None, 'marrmot_PRMS':None}  # 'HBV':None, 'hbvhy': None, 'SACSMA_snow':None, 'SACSMA':None,\n",
    "args_list = {'dPLHBV_dyn': hbvhyArgs_d, 'SACSMA_snow':sacsmaSnowArgs, 'marrmot_PRMS':prmsArgs}   # 'hbvhy': hbvhyArgs, 'HBV' : hbvArgs, 'SACSMA_snow':None, 'SACSMA': sacsmaArgs,\n",
    "ENSEMBLE_TYPE = 'max'  # 'median', 'avg', 'max', 'softmax'\n",
    "\n",
    "# Load test observations and predictions from a prior run.\n",
    "pred_path = os.path.join(out_dir, 'multimodels', '671_sites_dp', 'output', 'preds_671_dPLHBVd_SACSMASnow_PRMS.npy')\n",
    "obs_path = os.path.join(out_dir, 'multimodels', '671_sites_dp', 'output', 'obs_671_dPLHBVd_SACSMASnow_PRMS.npy')\n",
    "preds = np.load(pred_path, allow_pickle=True).item()\n",
    "obs = np.load(obs_path, allow_pickle=True).item()\n",
    "\n",
    "model_output = preds\n",
    "y_obs = obs\n",
    "\n",
    "# Initialize\n",
    "flow_preds = []\n",
    "flow_obs = None\n",
    "obs_trig = False\n",
    "\n",
    "# Concatenate individual model predictions, and observation data.\n",
    "for i, mod in enumerate(args_list):\n",
    "    args = args_list[mod]\n",
    "    mod_out = model_output[mod]\n",
    "    y_ob = y_obs[mod]\n",
    "\n",
    "    print(mod)\n",
    "\n",
    "    if mod in ['HBV', 'SACSMA', 'SACSMA_snow', 'marrmot_PRMS']:\n",
    "        # Hydro models are tested in batches, so we concatenate them and select\n",
    "        # the desired flow.\n",
    "        # Note: modified HBV already has this preparation done during testing.\n",
    "\n",
    "        # Get flow predictions and swap axes to get shape [basins, days]\n",
    "        pred = np.swapaxes(torch.cat([d[\"flow_sim\"] for d in mod_out], dim=1).squeeze().numpy(), 0, 1)\n",
    "\n",
    "        if obs_trig == False:\n",
    "            # dPLHBV uses GAGES while the other hydro models use CAMELS data. This means small \n",
    "            # e-5 variation in observation data between the two. This is averaged if both models\n",
    "            # are used, but to avoid double-counting data from multiply hydro models, use a trigger.\n",
    "            obs = np.swapaxes(y_ob[:, :, args[\"target\"].index(\"00060_Mean\")].numpy(), 0, 1)\n",
    "            obs_trig = True\n",
    "            dup = False\n",
    "        else:\n",
    "            dup = True\n",
    "\n",
    "    elif mod in ['dPLHBV_dyn']:\n",
    "        pred = mod_out[:,:,0][:,365:] # Set dim2 = 0 to get streamflow Qr\n",
    "        obs = y_ob.squeeze()[:,365:]\n",
    "        dup = False\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type in `models`.\")\n",
    "    \n",
    "    if i == 0:\n",
    "        tmp_pred = pred\n",
    "        tmp_obs = obs\n",
    "    elif i == 1:\n",
    "        tmp_pred = np.stack((tmp_pred, pred), axis=2)\n",
    "        if not dup:\n",
    "            # Avoid double-counting GAGES obs.\n",
    "            tmp_obs = np.stack((tmp_obs, obs), axis=2)\n",
    "    else:\n",
    "        # Combine outputs of >3 models.\n",
    "        tmp_pred = np.concatenate((tmp_pred,np.expand_dims(pred, 2)), axis=2)\n",
    "        if not dup:\n",
    "            # Avoid double-counting GAGES obs.\n",
    "            tmp_obs = np.concatenate((tmp_obs,np.expand_dims(obs, 2)), axis=2)\n",
    "\n",
    "preds = tmp_pred\n",
    "obs = tmp_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.68206453, 0.04178718, 0.04005739],\n",
       "        [0.6691796 , 0.15529171, 0.11451818],\n",
       "        [0.66096807, 0.28792492, 0.20852403],\n",
       "        ...,\n",
       "        [0.8316542 , 1.36070156, 1.47097933],\n",
       "        [0.9395818 , 1.60485446, 1.63182008],\n",
       "        [1.1111125 , 1.95312655, 1.91992617]],\n",
       "\n",
       "       [[1.0886465 , 0.30196935, 0.22478479],\n",
       "        [1.025554  , 0.63441604, 0.54297   ],\n",
       "        [0.95555204, 0.75878251, 0.72244602],\n",
       "        ...,\n",
       "        [0.65361506, 0.63856089, 0.87026596],\n",
       "        [0.658928  , 0.66052788, 0.95191711],\n",
       "        [0.6488367 , 0.62889987, 0.8994624 ]],\n",
       "\n",
       "       [[0.45831633, 0.02072911, 0.02349203],\n",
       "        [0.4823348 , 0.09775467, 0.08600431],\n",
       "        [0.4811496 , 0.19010772, 0.15757091],\n",
       "        ...,\n",
       "        [0.5142777 , 0.79288632, 1.0482471 ],\n",
       "        [0.5479347 , 0.84627336, 1.09326005],\n",
       "        [0.57785803, 0.8880285 , 1.10479856]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8393843 , 0.20238577, 0.0420501 ],\n",
       "        [0.8366754 , 0.2631875 , 0.05698096],\n",
       "        [0.8341537 , 0.27341762, 0.06038158],\n",
       "        ...,\n",
       "        [0.8563844 , 0.43005475, 0.08504984],\n",
       "        [0.84207505, 0.41748184, 0.08275375],\n",
       "        [0.82972795, 0.40676057, 0.08052753]],\n",
       "\n",
       "       [[0.58320355, 0.00571625, 0.00361477],\n",
       "        [0.5823564 , 0.00782637, 0.00534628],\n",
       "        [0.5815113 , 0.00902264, 0.00643683],\n",
       "        ...,\n",
       "        [0.36712772, 0.05098156, 0.04001843],\n",
       "        [0.36658615, 0.05018821, 0.03499828],\n",
       "        [0.3660536 , 0.04950969, 0.0309677 ]],\n",
       "\n",
       "       [[0.09028151, 0.13558374, 0.01092425],\n",
       "        [0.08113345, 0.17739253, 0.01433971],\n",
       "        [0.07321094, 0.17108224, 0.01179233],\n",
       "        ...,\n",
       "        [0.47700787, 0.68664551, 0.27877131],\n",
       "        [0.39193898, 0.58662033, 0.19232103],\n",
       "        [0.3262965 , 0.50539178, 0.13268054]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.67010016, 0.67010128],\n",
       "        [0.63534618, 0.63534725],\n",
       "        [0.62448556, 0.62448663],\n",
       "        ...,\n",
       "        [0.69399352, 0.69399476],\n",
       "        [0.81671851, 0.81671995],\n",
       "        [0.93509925, 0.93510085]],\n",
       "\n",
       "       [[0.9127725 , 0.91277152],\n",
       "        [0.82746666, 0.82746577],\n",
       "        [0.7506914 , 0.75069064],\n",
       "        ...,\n",
       "        [0.2687134 , 0.26871312],\n",
       "        [0.30710103, 0.30710071],\n",
       "        [0.3198969 , 0.31989658]],\n",
       "\n",
       "       [[0.32544019, 0.32544002],\n",
       "        [0.35272659, 0.3527264 ],\n",
       "        [0.3620439 , 0.36204371],\n",
       "        ...,\n",
       "        [0.38267507, 0.38267487],\n",
       "        [0.3986476 , 0.39864737],\n",
       "        [0.41462012, 0.41461989]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.11595911, 0.11595792],\n",
       "        [0.11595911, 0.11595792],\n",
       "        [0.11595911, 0.11595792],\n",
       "        ...,\n",
       "        [0.19326518, 0.19326322],\n",
       "        [0.18774332, 0.18774141],\n",
       "        [0.18774332, 0.18774141]],\n",
       "\n",
       "       [[0.02008291, 0.02008214],\n",
       "        [0.02126426, 0.02126344],\n",
       "        [0.02244561, 0.02244474],\n",
       "        ...,\n",
       "        [0.00531607, 0.00531586],\n",
       "        [0.00531607, 0.00531586],\n",
       "        [0.00472539, 0.00472521]],\n",
       "\n",
       "       [[0.2646335 , 0.26463178],\n",
       "        [0.2646335 , 0.26463178],\n",
       "        [0.2646335 , 0.26463178],\n",
       "        ...,\n",
       "        [0.43177045, 0.4317677 ],\n",
       "        [0.41436035, 0.41435769],\n",
       "        [0.40043227, 0.4004297 ]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGML_STemp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
